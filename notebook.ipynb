{"cells":[{"source":"![Credit card being held in hand](credit_card.jpg)\n\nCommercial banks receive _a lot_ of applications for credit cards. Many of them get rejected for many reasons, like high loan balances, low income levels, or too many inquiries on an individual's credit report, for example. Manually analyzing these applications is mundane, error-prone, and time-consuming (and time is money!). Luckily, this task can be automated with the power of machine learning and pretty much every commercial bank does so nowadays. In this workbook, you will build an automatic credit card approval predictor using machine learning techniques, just like real banks do.\n\n### The Data\n\nThe data is a small subset of the Credit Card Approval dataset from the UCI Machine Learning Repository showing the credit card applications a bank receives. This dataset has been loaded as a `pandas` DataFrame called `cc_apps`. The last column in the dataset is the target value.","metadata":{},"id":"35aebf2e-0635-4fef-bc9a-877b6a20fb13","cell_type":"markdown"},{"source":"# Import necessary libraries\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import GridSearchCV\n\n# Load the dataset\ncc_apps = pd.read_csv(\"cc_approvals.data\", header=None) \ncc_apps.head()","metadata":{"executionCancelledAt":null,"executionTime":48,"lastExecutedAt":1749573599330,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Import necessary libraries\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import GridSearchCV\n\n# Load the dataset\ncc_apps = pd.read_csv(\"cc_approvals.data\", header=None) \ncc_apps.head()","outputsMetadata":{"0":{"height":550,"type":"dataFrame","tableState":{"customFilter":{"const":{"type":"boolean","valid":true,"value":true},"id":"6e119c37-4b3b-4361-b407-597a8b3fc2ff","nodeType":"const"}},"chartState":{"chartModel":{"modelType":"range","chartId":"id-p4tdum438oh","chartType":"groupedColumn","chartThemeName":"datalabTheme","chartOptions":{"common":{"animation":{"enabled":true}}},"chartPalette":{"fills":["#6568A0","#43D7A4","#4095DB","#FACC5F","#CAE279","#F08083","#5BCDF2","#F099DC","#965858","#7DB64F","#A98954"],"strokes":["#6568A0","#43D7A4","#4095DB","#FACC5F","#CAE279","#F08083","#5BCDF2","#F099DC","#965858","#7DB64F","#A98954"],"up":{"fill":"#459d55","stroke":"#1e652e"},"down":{"fill":"#ef5452","stroke":"#a82529"},"neutral":{"fill":"#b5b5b5","stroke":"#575757"},"altUp":{"fill":"#5090dc","stroke":"#2b5c95"},"altDown":{"fill":"#ffa03a","stroke":"#cc6f10"},"altNeutral":{"fill":"#b5b5b5","stroke":"#575757"}},"cellRange":{"rowStartIndex":null,"rowStartPinned":null,"rowEndIndex":null,"rowEndPinned":null,"columns":[]},"switchCategorySeries":false,"suppressChartRanges":false,"aggFunc":"sum","unlinkChart":false,"version":"32.2.2"},"rangeChartModel":{"aggFunc":"sum","rangeColumns":[],"switchCategorySeries":false}}}},"lastExecutedByKernel":"5be7b519-696e-4093-9ac7-06f46107fff8","visualizeDataframe":false,"version":"ag-charts-v1"},"id":"6e86b1e8-a3fa-4b09-982f-795f218bd1a6","cell_type":"code","execution_count":40,"outputs":[{"output_type":"execute_result","data":{"application/com.datacamp.data-table.v2+json":{"table":{"schema":{"fields":[{"name":"index","type":"integer"},{"name":"0","type":"string"},{"name":"1","type":"string"},{"name":"2","type":"number"},{"name":"3","type":"string"},{"name":"4","type":"string"},{"name":"5","type":"string"},{"name":"6","type":"string"},{"name":"7","type":"number"},{"name":"8","type":"string"},{"name":"9","type":"string"},{"name":"10","type":"integer"},{"name":"11","type":"string"},{"name":"12","type":"integer"},{"name":"13","type":"string"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":{"0":["b","a","a","b","b"],"1":["30.83","58.67","24.50","27.83","20.17"],"2":[0,4.46,0.5,1.54,5.625],"3":["u","u","u","u","u"],"4":["g","g","g","g","g"],"5":["w","q","q","w","w"],"6":["v","h","h","v","v"],"7":[1.25,3.04,1.5,3.75,1.71],"8":["t","t","t","t","t"],"9":["t","t","f","t","f"],"10":[1,6,0,5,0],"11":["g","g","g","g","s"],"12":[0,560,824,3,0],"13":["+","+","+","+","+"],"index":[0,1,2,3,4]}},"total_rows":5,"truncation_type":null},"text/plain":"  0      1      2  3  4  5  6     7  8  9   10 11   12 13\n0  b  30.83  0.000  u  g  w  v  1.25  t  t   1  g    0  +\n1  a  58.67  4.460  u  g  q  h  3.04  t  t   6  g  560  +\n2  a  24.50  0.500  u  g  q  h  1.50  t  f   0  g  824  +\n3  b  27.83  1.540  u  g  w  v  3.75  t  t   5  g    3  +\n4  b  20.17  5.625  u  g  w  v  1.71  t  f   0  s    0  +","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>b</td>\n      <td>30.83</td>\n      <td>0.000</td>\n      <td>u</td>\n      <td>g</td>\n      <td>w</td>\n      <td>v</td>\n      <td>1.25</td>\n      <td>t</td>\n      <td>t</td>\n      <td>1</td>\n      <td>g</td>\n      <td>0</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>a</td>\n      <td>58.67</td>\n      <td>4.460</td>\n      <td>u</td>\n      <td>g</td>\n      <td>q</td>\n      <td>h</td>\n      <td>3.04</td>\n      <td>t</td>\n      <td>t</td>\n      <td>6</td>\n      <td>g</td>\n      <td>560</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>a</td>\n      <td>24.50</td>\n      <td>0.500</td>\n      <td>u</td>\n      <td>g</td>\n      <td>q</td>\n      <td>h</td>\n      <td>1.50</td>\n      <td>t</td>\n      <td>f</td>\n      <td>0</td>\n      <td>g</td>\n      <td>824</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>b</td>\n      <td>27.83</td>\n      <td>1.540</td>\n      <td>u</td>\n      <td>g</td>\n      <td>w</td>\n      <td>v</td>\n      <td>3.75</td>\n      <td>t</td>\n      <td>t</td>\n      <td>5</td>\n      <td>g</td>\n      <td>3</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>b</td>\n      <td>20.17</td>\n      <td>5.625</td>\n      <td>u</td>\n      <td>g</td>\n      <td>w</td>\n      <td>v</td>\n      <td>1.71</td>\n      <td>t</td>\n      <td>f</td>\n      <td>0</td>\n      <td>s</td>\n      <td>0</td>\n      <td>+</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{"application/com.datacamp.data-table.v2+json":{"status":"success"}},"execution_count":40}]},{"source":"\n### 1. Preprocessing the data\n\n","metadata":{},"cell_type":"markdown","id":"4fc92623-e3d2-4f6b-afc5-423a690cd456"},{"source":"# This code creates a copy of the DataFrame `cc_apps` and assigns it to `cc_apps_cleaned`.\n# It then replaces all occurrences of the '?' character in `cc_apps_cleaned` with NaN (Not a Number) values.\n\ncc_apps_cleaned = cc_apps.copy()\ncc_apps_cleaned.replace('?', np.nan, inplace=True)","metadata":{"executionCancelledAt":null,"executionTime":55,"lastExecutedAt":1749573599386,"lastExecutedByKernel":"5be7b519-696e-4093-9ac7-06f46107fff8","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# This code creates a copy of the DataFrame `cc_apps` and assigns it to `cc_apps_cleaned`.\n# It then replaces all occurrences of the '?' character in `cc_apps_cleaned` with NaN (Not a Number) values.\n\ncc_apps_cleaned = cc_apps.copy()\ncc_apps_cleaned.replace('?', np.nan, inplace=True)","outputsMetadata":{"0":{"height":500,"type":"dataFrame","tableState":{}}}},"cell_type":"code","id":"6a254d54-b4a1-4a8f-8ae4-1a4fd0bb8a3b","outputs":[],"execution_count":41},{"source":"print(cc_apps_cleaned.dtypes)","metadata":{"executionCancelledAt":null,"executionTime":49,"lastExecutedAt":1749573599435,"lastExecutedByKernel":"5be7b519-696e-4093-9ac7-06f46107fff8","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"print(cc_apps_cleaned.dtypes)","outputsMetadata":{"0":{"height":332,"type":"stream"}}},"cell_type":"code","id":"4ddb9693-6472-4d02-86ab-15034333e7e7","outputs":[{"output_type":"stream","name":"stdout","text":"0      object\n1      object\n2     float64\n3      object\n4      object\n5      object\n6      object\n7     float64\n8      object\n9      object\n10      int64\n11     object\n12      int64\n13     object\ndtype: object\n"}],"execution_count":42},{"source":"# This code prints the count of unique values in column 0 of the cc_apps_cleaned DataFrame.\ncc_apps_cleaned[0].value_counts()","metadata":{"executionCancelledAt":null,"executionTime":52,"lastExecutedAt":1749573599487,"lastExecutedByKernel":"5be7b519-696e-4093-9ac7-06f46107fff8","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# This code prints the count of unique values in column 0 of the cc_apps_cleaned DataFrame.\ncc_apps_cleaned[0].value_counts()","outputsMetadata":{"0":{"height":550,"type":"dataFrame","tableState":{}}}},"cell_type":"code","id":"2a06b62c-c089-4549-893b-31bba8be9828","outputs":[{"output_type":"execute_result","data":{"application/com.datacamp.data-table.v2+json":{"table":{"schema":{"fields":[{"name":"index","type":"string"},{"name":"0","type":"integer"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":{"0":[468,210],"index":["b","a"]}},"total_rows":2,"truncation_type":null},"text/plain":"b    468\na    210\nName: 0, dtype: int64"},"metadata":{"application/com.datacamp.data-table.v2+json":{"status":"success"}},"execution_count":43}],"execution_count":43},{"source":"# The code `cc_apps_cleaned.mean()` performs the following actions:\n\n# 1. **Calculate Mean**: The `mean()` method calculates the mean (average) of each numerical column in the DataFrame `cc_apps_cleaned`.\n# 2. **Return Result**: It returns a Series where the index is the column names and the values are the mean of each column.\n\ncc_apps_cleaned.mean()","metadata":{"executionCancelledAt":null,"executionTime":53,"lastExecutedAt":1749573599540,"lastExecutedByKernel":"5be7b519-696e-4093-9ac7-06f46107fff8","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# The code `cc_apps_cleaned.mean()` performs the following actions:\n\n# 1. **Calculate Mean**: The `mean()` method calculates the mean (average) of each numerical column in the DataFrame `cc_apps_cleaned`.\n# 2. **Return Result**: It returns a Series where the index is the column names and the values are the mean of each column.\n\ncc_apps_cleaned.mean()","outputsMetadata":{"0":{"height":550,"type":"dataFrame","tableState":{}}}},"cell_type":"code","id":"306a8582-afdd-4a5c-a38b-3b2ace48c201","outputs":[{"output_type":"execute_result","data":{"application/com.datacamp.data-table.v2+json":{"table":{"schema":{"fields":[{"name":"index","type":"integer"},{"name":"0","type":"number"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":{"0":[4.7587246377,2.2234057971,2.4,1017.3855072464],"index":[2,7,10,12]}},"total_rows":4,"truncation_type":null},"text/plain":"2        4.758725\n7        2.223406\n10       2.400000\n12    1017.385507\ndtype: float64"},"metadata":{"application/com.datacamp.data-table.v2+json":{"status":"success"}},"execution_count":44}],"execution_count":44},{"source":"# This code iterates over each column in the DataFrame `cc_apps_cleaned` and fills missing values based on \n#the column's data type.\n\nfor col in cc_apps_cleaned.columns:\n    # Check if the column's data type is 'object' (typically used for categorical data)\n    if cc_apps_cleaned[col].dtype == \"object\":\n        # Find the most frequent value in the column\n        most_frequent = cc_apps_cleaned[col].value_counts().index[0]\n        # Fill missing values in the column with the most frequent value\n        cc_apps_cleaned[col].fillna(most_frequent, inplace=True)\n    else:\n        # Calculate the mean of the column\n        mean_value = cc_apps_cleaned[col].mean()\n        # Fill missing values in the column with the mean value\n        cc_apps_cleaned[col].fillna(mean_value, inplace=True)","metadata":{"executionCancelledAt":null,"executionTime":58,"lastExecutedAt":1749573599598,"lastExecutedByKernel":"5be7b519-696e-4093-9ac7-06f46107fff8","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# This code iterates over each column in the DataFrame `cc_apps_cleaned` and fills missing values based on \n#the column's data type.\n\nfor col in cc_apps_cleaned.columns:\n    # Check if the column's data type is 'object' (typically used for categorical data)\n    if cc_apps_cleaned[col].dtype == \"object\":\n        # Find the most frequent value in the column\n        most_frequent = cc_apps_cleaned[col].value_counts().index[0]\n        # Fill missing values in the column with the most frequent value\n        cc_apps_cleaned[col].fillna(most_frequent, inplace=True)\n    else:\n        # Calculate the mean of the column\n        mean_value = cc_apps_cleaned[col].mean()\n        # Fill missing values in the column with the mean value\n        cc_apps_cleaned[col].fillna(mean_value, inplace=True)"},"cell_type":"code","id":"525210ec-adcc-430f-a75d-4d899a7d50dc","outputs":[],"execution_count":45},{"source":"# This code changes text columns in the DataFrame `cc_apps_cleaned` into numbers.\n\n# It uses a function called `pd.get_dummies` from the pandas library to do this.\n\n# `drop_first=True` means it will remove the first category of each text column to avoid having extra columns that say the same thing.\n\n# The new DataFrame with the numbers instead of text is called `cc_app_dummies`.\n\ncc_app_dummies = pd.get_dummies(cc_apps_cleaned, drop_first=True)\nprint(cc_app_dummies.head())","metadata":{"executionCancelledAt":null,"executionTime":72,"lastExecutedAt":1749573599671,"lastExecutedByKernel":"5be7b519-696e-4093-9ac7-06f46107fff8","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# This code changes text columns in the DataFrame `cc_apps_cleaned` into numbers.\n\n# It uses a function called `pd.get_dummies` from the pandas library to do this.\n\n# `drop_first=True` means it will remove the first category of each text column to avoid having extra columns that say the same thing.\n\n# The new DataFrame with the numbers instead of text is called `cc_app_dummies`.\n\ncc_app_dummies = pd.get_dummies(cc_apps_cleaned, drop_first=True)\nprint(cc_app_dummies.head())","outputsMetadata":{"0":{"height":185,"type":"stream"}}},"cell_type":"code","id":"ac7add14-35b2-47ac-8eb8-7a85975d0f6b","outputs":[{"output_type":"stream","name":"stdout","text":"       2     7  10   12  0_b  1_15.17  ...  6_z  8_t  9_t  11_p  11_s  13_-\n0  0.000  1.25   1    0    1        0  ...    0    1    1     0     0     0\n1  4.460  3.04   6  560    0        0  ...    0    1    1     0     0     0\n2  0.500  1.50   0  824    0        0  ...    0    1    0     0     0     0\n3  1.540  3.75   5    3    1        0  ...    0    1    1     0     0     0\n4  5.625  1.71   0    0    1        0  ...    0    1    0     0     1     0\n\n[5 rows x 383 columns]\n"}],"execution_count":46},{"source":"**1. Prepare the data for Modeling**","metadata":{},"cell_type":"markdown","id":"61579c0a-6289-4f99-a86f-41f2f56faa26"},{"source":"print(cc_app_dummies.columns)","metadata":{"executionCancelledAt":null,"executionTime":54,"lastExecutedAt":1749573599725,"lastExecutedByKernel":"5be7b519-696e-4093-9ac7-06f46107fff8","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"print(cc_app_dummies.columns)","outputsMetadata":{"0":{"height":143,"type":"stream"}}},"cell_type":"code","id":"4fead329-f810-4896-8254-48f10d9b922b","outputs":[{"output_type":"stream","name":"stdout","text":"Index([        2,         7,        10,        12,     '0_b', '1_15.17',\n       '1_15.75', '1_15.83', '1_15.92', '1_16.00',\n       ...\n           '6_j',     '6_n',     '6_o',     '6_v',     '6_z',     '8_t',\n           '9_t',    '11_p',    '11_s',    '13_-'],\n      dtype='object', length=383)\n"}],"execution_count":47},{"source":"# This code is used to separate the features (X) and the target variable (y) from the DataFrame `cc_app_dummies`.\n\n# `X` will contain all the columns except the last one.\n# `iloc[:, :-1]` selects all rows and all columns except the last one.\nX = cc_app_dummies.iloc[:, :-1].values\n\n# `y` will contain only the last column.\n# `iloc[:, -1]` selects all rows and only the last column.\n# Note: There is a typo in the original code. It should be `iloc` instead of `illoc`.\ny = cc_app_dummies.iloc[:, -1].values","metadata":{"executionCancelledAt":null,"executionTime":50,"lastExecutedAt":1749573599775,"lastExecutedByKernel":"5be7b519-696e-4093-9ac7-06f46107fff8","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# This code is used to separate the features (X) and the target variable (y) from the DataFrame `cc_app_dummies`.\n\n# `X` will contain all the columns except the last one.\n# `iloc[:, :-1]` selects all rows and all columns except the last one.\nX = cc_app_dummies.iloc[:, :-1].values\n\n# `y` will contain only the last column.\n# `iloc[:, -1]` selects all rows and only the last column.\n# Note: There is a typo in the original code. It should be `iloc` instead of `illoc`.\ny = cc_app_dummies.iloc[:, -1].values"},"cell_type":"code","id":"caf99fc1-8606-409f-bef7-1ad48bf7b6a1","outputs":[],"execution_count":48},{"source":"# This code splits the dataset into training and testing sets.\n\n# `train_test_split` is a function from the `sklearn.model_selection` module.\n# It takes the features (X) and the target variable (y) and splits them into training and testing sets.\n\n# `test_size=0.2` means that 20% of the data will be used for testing, and 80% will be used for training.\n\n# `random_state=42` is a seed value to ensure that the split is reproducible. \n# Using the same seed value will always produce the same split.\n\n# `X_train` and `y_train` will contain the training data.\n# `X_test` and `y_test` will contain the testing data.\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"executionCancelledAt":null,"executionTime":51,"lastExecutedAt":1749573599827,"lastExecutedByKernel":"5be7b519-696e-4093-9ac7-06f46107fff8","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# This code splits the dataset into training and testing sets.\n\n# `train_test_split` is a function from the `sklearn.model_selection` module.\n# It takes the features (X) and the target variable (y) and splits them into training and testing sets.\n\n# `test_size=0.2` means that 20% of the data will be used for testing, and 80% will be used for training.\n\n# `random_state=42` is a seed value to ensure that the split is reproducible. \n# Using the same seed value will always produce the same split.\n\n# `X_train` and `y_train` will contain the training data.\n# `X_test` and `y_test` will contain the testing data.\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"},"cell_type":"code","id":"90020425-4d13-43e9-bc58-d4ffd3b98d90","outputs":[],"execution_count":49},{"source":"# This code scales the features in the training and test sets using StandardScaler from the sklearn library.\n\n# StandardScaler standardizes features by removing the mean and scaling to unit variance.\n# This means each feature will have a mean of 0 and a standard deviation of 1.\n\n# Create an instance of StandardScaler\nscaler = StandardScaler()\n\n# Fit the scaler on the training data and transform the training data\n# `fit_transform` calculates the mean and standard deviation on the training data and scales it accordingly.\nX_train_scaled = scaler.fit_transform(X_train)\n\n# Transform the test data using the same scaler\n# `transform` scales the test data using the mean and standard deviation calculated from the training data.\nX_test_scaled = scaler.transform(X_test)\n\n\nprint(np.mean(X), np.std(X))\nprint(np.mean(X_train_scaled), np.std(X_test_scaled))","metadata":{"executionCancelledAt":null,"executionTime":56,"lastExecutedAt":1749573599883,"lastExecutedByKernel":"5be7b519-696e-4093-9ac7-06f46107fff8","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# This code scales the features in the training and test sets using StandardScaler from the sklearn library.\n\n# StandardScaler standardizes features by removing the mean and scaling to unit variance.\n# This means each feature will have a mean of 0 and a standard deviation of 1.\n\n# Create an instance of StandardScaler\nscaler = StandardScaler()\n\n# Fit the scaler on the training data and transform the training data\n# `fit_transform` calculates the mean and standard deviation on the training data and scales it accordingly.\nX_train_scaled = scaler.fit_transform(X_train)\n\n# Transform the test data using the same scaler\n# `transform` scales the test data using the mean and standard deviation calculated from the training data.\nX_test_scaled = scaler.transform(X_test)\n\n\nprint(np.mean(X), np.std(X))\nprint(np.mean(X_train_scaled), np.std(X_test_scaled))","outputsMetadata":{"0":{"height":59,"type":"stream"}}},"cell_type":"code","id":"bfe137a2-074f-4329-b449-3f70dd3d51cf","outputs":[{"output_type":"stream","name":"stdout","text":"2.703086994460885 271.4041878829651\n5.315659219504316e-18 0.8309442044804253\n"}],"execution_count":50},{"source":"**3. Training the Model**","metadata":{},"cell_type":"markdown","id":"0334bffa-32ce-4cc5-8f0e-bd1708a34125"},{"source":"# Create an instance of LogisticRegression\nlogreg = LogisticRegression()\n\n# Fit the logistic regression model on the scaled training data\n# `fit` trains the model using the training data and the corresponding labels\nlogreg.fit(X_train_scaled, y_train)\n\n# Predict the labels for the scaled test data\n# `predict` uses the trained model to make predictions on the test data\ny_pred = logreg.predict(X_test_scaled)\n\n# Compute the confusion matrix to evaluate the accuracy of the classification\n# `confusion_matrix` compares the true labels (y_test) with the predicted labels (y_pred)\nconf_matrix = confusion_matrix(y_test, y_pred)\n\n# The confusion matrix is stored in the variable `conf_matrix`\nprint(conf_matrix)\n\n#The output is a confusion matrix, which is a table used to evaluate the performance of a classification model. It compares the true labels (y_test) with the predicted labels (y_pred) and shows the counts of true positive, true negative, false positive, and false negative predictions. The confusion matrix helps in understanding the accuracy, precision, recall, and other performance metrics of the model.","metadata":{"executionCancelledAt":null,"executionTime":309,"lastExecutedAt":1749573600192,"lastExecutedByKernel":"5be7b519-696e-4093-9ac7-06f46107fff8","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Create an instance of LogisticRegression\nlogreg = LogisticRegression()\n\n# Fit the logistic regression model on the scaled training data\n# `fit` trains the model using the training data and the corresponding labels\nlogreg.fit(X_train_scaled, y_train)\n\n# Predict the labels for the scaled test data\n# `predict` uses the trained model to make predictions on the test data\ny_pred = logreg.predict(X_test_scaled)\n\n# Compute the confusion matrix to evaluate the accuracy of the classification\n# `confusion_matrix` compares the true labels (y_test) with the predicted labels (y_pred)\nconf_matrix = confusion_matrix(y_test, y_pred)\n\n# The confusion matrix is stored in the variable `conf_matrix`\nprint(conf_matrix)\n\n#The output is a confusion matrix, which is a table used to evaluate the performance of a classification model. It compares the true labels (y_test) with the predicted labels (y_pred) and shows the counts of true positive, true negative, false positive, and false negative predictions. The confusion matrix helps in understanding the accuracy, precision, recall, and other performance metrics of the model.","outputsMetadata":{"0":{"height":59,"type":"stream"}}},"cell_type":"code","id":"34c24541-c722-4fbe-a722-f726cb139f9f","outputs":[{"output_type":"stream","name":"stdout","text":"[[52 18]\n [12 56]]\n"}],"execution_count":51},{"source":"**4. Finding the best scoring model**","metadata":{},"cell_type":"markdown","id":"f2942b24-ff92-49ef-bc7d-b9eff9b90ac3"},{"source":"# Define a dictionary `params_grid` that contains the hyperparameters to be tuned.\n# \"C\" is the inverse of regularization strength; smaller values specify stronger regularization.\n# \"penalty\" specifies the norm used in the penalization ('l1' for L1 norm, 'l2' for L2 norm).\n# \"solver\" specifies the algorithm to use in the optimization problem ('liblinear' is a good choice for small datasets).\nparams_grid = {\n    \"C\": [0.01, 0.1, 1, 10],\n    \"penalty\": ['l1', 'l2'],\n    \"solver\":['liblinear']\n}\n\n# Create an instance of GridSearchCV.\n# `estimator` is the model to be used (LogisticRegression in this case).\n# `param_grid` is the dictionary of hyperparameters to be tuned.\n# `cv` is the number of cross-validation folds (5 in this case).\ngrid_search = GridSearchCV(\n    estimator = LogisticRegression(),\n    param_grid = params_grid,\n    cv = 5\n)\n\n# Fit the GridSearchCV object to the scaled training data.\n# This will train the model for each combination of hyperparameters in `param_grid`\n# and evaluate it using 5-fold cross-validation.\ngrid_search.fit(X_train_scaled, y_train)\n\n# `grid_search.best_score_` contains the best mean cross-validated score obtained\n# during the grid search.\ngrid_search.best_score_","metadata":{"executionCancelledAt":null,"executionTime":5604,"lastExecutedAt":1749573605796,"lastExecutedByKernel":"5be7b519-696e-4093-9ac7-06f46107fff8","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Define a dictionary `params_grid` that contains the hyperparameters to be tuned.\n# \"C\" is the inverse of regularization strength; smaller values specify stronger regularization.\n# \"penalty\" specifies the norm used in the penalization ('l1' for L1 norm, 'l2' for L2 norm).\n# \"solver\" specifies the algorithm to use in the optimization problem ('liblinear' is a good choice for small datasets).\nparams_grid = {\n    \"C\": [0.01, 0.1, 1, 10],\n    \"penalty\": ['l1', 'l2'],\n    \"solver\":['liblinear']\n}\n\n# Create an instance of GridSearchCV.\n# `estimator` is the model to be used (LogisticRegression in this case).\n# `param_grid` is the dictionary of hyperparameters to be tuned.\n# `cv` is the number of cross-validation folds (5 in this case).\ngrid_search = GridSearchCV(\n    estimator = LogisticRegression(),\n    param_grid = params_grid,\n    cv = 5\n)\n\n# Fit the GridSearchCV object to the scaled training data.\n# This will train the model for each combination of hyperparameters in `param_grid`\n# and evaluate it using 5-fold cross-validation.\ngrid_search.fit(X_train_scaled, y_train)\n\n# `grid_search.best_score_` contains the best mean cross-validated score obtained\n# during the grid search.\ngrid_search.best_score_","outputsMetadata":{"0":{"height":38,"type":"stream"}}},"cell_type":"code","id":"d3cb48e7-253d-4537-be09-59f3f38111a4","outputs":[{"output_type":"execute_result","data":{"text/plain":"0.8768550368550369"},"metadata":{},"execution_count":52}],"execution_count":52},{"source":"# `grid_search.best_estimator_` retrieves the model that gave the best performance\n# during the grid search. This model is already trained on the entire training set\n# using the best combination of hyperparameters found during the grid search.\nbest_model = grid_search.best_estimator_\n\n# `print(best_model)` outputs the details of the best model, including the hyperparameters\n# that were used. This helps in understanding which combination of hyperparameters\n# resulted in the best performance.\nprint(best_model)","metadata":{"executionCancelledAt":null,"executionTime":54,"lastExecutedAt":1749573605850,"lastExecutedByKernel":"5be7b519-696e-4093-9ac7-06f46107fff8","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# `grid_search.best_estimator_` retrieves the model that gave the best performance\n# during the grid search. This model is already trained on the entire training set\n# using the best combination of hyperparameters found during the grid search.\nbest_model = grid_search.best_estimator_\n\n# `print(best_model)` outputs the details of the best model, including the hyperparameters\n# that were used. This helps in understanding which combination of hyperparameters\n# resulted in the best performance.\nprint(best_model)","outputsMetadata":{"0":{"height":38,"type":"stream"}}},"cell_type":"code","id":"0999557e-57e8-4594-a877-358b0640e650","outputs":[{"output_type":"stream","name":"stdout","text":"LogisticRegression(C=1, penalty='l1', solver='liblinear')\n"}],"execution_count":53},{"source":"# `best_model.fit(X_train_scaled, y_train)` trains the best model found during the grid search\n# on the scaled training data (`X_train_scaled`) and the corresponding labels (`y_train`).\n# This step ensures that the model is fitted to the training data before making predictions.\n\nbest_model.fit(X_train_scaled, y_train)\n\n# `best_score = best_model.score(X_test_scaled, y_test)` evaluates the performance of the trained model\n# on the scaled test data (`X_test_scaled`) and the corresponding labels (`y_test`).\n# The `score` method typically returns the mean accuracy for classification models or the R^2 score for regression models.\n# The result is stored in the variable `best_score`.\n\nbest_score = best_model.score(X_test_scaled, y_test)\n\n# The `print(best_score)` statement outputs the performance score of the model on the test data.\n# This helps in understanding how well the model generalizes to unseen data.\n\nprint(best_score)","metadata":{"executionCancelledAt":null,"executionTime":55,"lastExecutedAt":1749573605906,"lastExecutedByKernel":"5be7b519-696e-4093-9ac7-06f46107fff8","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# `best_model.fit(X_train_scaled, y_train)` trains the best model found during the grid search\n# on the scaled training data (`X_train_scaled`) and the corresponding labels (`y_train`).\n# This step ensures that the model is fitted to the training data before making predictions.\n\nbest_model.fit(X_train_scaled, y_train)\n\n# `best_score = best_model.score(X_test_scaled, y_test)` evaluates the performance of the trained model\n# on the scaled test data (`X_test_scaled`) and the corresponding labels (`y_test`).\n# The `score` method typically returns the mean accuracy for classification models or the R^2 score for regression models.\n# The result is stored in the variable `best_score`.\n\nbest_score = best_model.score(X_test_scaled, y_test)\n\n# The `print(best_score)` statement outputs the performance score of the model on the test data.\n# This helps in understanding how well the model generalizes to unseen data.\n\nprint(best_score)","outputsMetadata":{"0":{"height":38,"type":"stream"}}},"cell_type":"code","id":"4a844161-5742-42be-9be9-eb6b8befea4e","outputs":[{"output_type":"stream","name":"stdout","text":"0.782608695652174\n"}],"execution_count":54}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.8.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"editor":"DataLab"},"nbformat":4,"nbformat_minor":5}